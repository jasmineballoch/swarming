# -*- coding: utf-8 -*-
"""gene_drive_swarming.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1xoeaOOJq5-CQyaoXorsVhcNCMxQfczD7
"""

from google.colab import drive
drive.mount('/content/drive')

import pandas as pd
import matplotlib.pyplot as plt
from matplotlib import cm
import matplotlib.colors
import numpy as np
import numpy.random
import datetime as dt
import datetime as datetime
import scipy
from scipy.signal import savgol_filter
import seaborn as sns


#Â Initial dataframe - from saved csv file
df = pd.read_csv('/content/drive/MyDrive/Datasets/summer_project_csv/QFS1_hetero_mixed/20220714_hetero_mixed_left/20220714_hetero_mixed_left.csv')
df.info()
df.head()


# Check missing values
missing_values_count = df.isnull().sum()
missing_values_count


df.head(-5)

# View data distribution for each variable
df.hist(bins=50, figsize = (12.0, 10.0))
plt.tight_layout(True)
plt.show()

# Reducing the dataframe to work with just coordinates/ID (copy of original object not just a slice) - could also filter size out here too - Alekos has suggested that we don't filter size as it is not all noise***
# Filter size fist before cutting and copying dataframe - DO NOT FILTER FOR SIZE

#df_size = df[df['size_mm2'] >= 25]
#df_size_2 = df_size[df_size['size_mm2'] <= 50]

df_red = df.iloc[:, 0:5].copy()
df_red

# Check size filter
df_red.hist(bins=50, figsize = (12.0, 10.0))
plt.tight_layout(True)
plt.show()

# Turn df into an array, smooth data and filter xyz values - savgol to increase precision of data

array_1 = df_red.to_numpy()
id = array_1[:,0]
datetime = array_1[:,1]
x_cm = array_1[:,2]
y_cm = array_1[:,3]
z_cm = array_1[:,4]

x_smooth = savgol_filter(x_cm, 63, 4)
y_smooth = savgol_filter(y_cm, 63, 4)
z_smooth = savgol_filter(z_cm, 63, 4)

array_2 = np.column_stack((id, datetime, x_smooth, y_smooth, z_smooth))
df_smoothed = pd.DataFrame(array_2, columns=['track_id', 'date_time', 'x', 'y', 'z'])
df_smoothed.head()

df_smoothed['x'] = df_smoothed.x.astype(float)
df_smoothed['y'] = df_smoothed.y.astype(float)
df_smoothed['z'] = df_smoothed.z.astype(float)
df_smoothed.head()

print(df_smoothed.z.min())
print(df_smoothed.z.max())

print(df_smoothed.y.min())
print(df_smoothed.y.max())


# Filter z axis - 180cm to 350cm along z axis
# Calibration with small cages showed that left cage marker is at -12.5 and right cage marker is at -15.5 ** change this depending on recording **
df_filtered = df_smoothed[df_smoothed['z'] <= 350]
df_filtered = df_filtered[df_filtered['z'] >= 180]
df_filtered = df_filtered[df_filtered['y'] >= -12.5]
df_filtered.info()
df_filtered.head(100)

print(df_filtered.y.min())
print(df_filtered.y.max())

df_filtered.head(-1)
df_filtered.head(10)

df_sort_time = df_filtered.sort_values(by=['date_time'])
df_sort_time.info()

# Sort IDs by time, group by track ID and total flying times
df_sort_time = df_filtered.sort_values(by=['date_time'])
df_grouped = df_sort_time.groupby('track_id')
df_sort_time.columns
df_3D = df_sort_time.loc[:,['track_id','date_time', 'x', 'y', 'z']].values
df_pre_fly = pd.DataFrame(data=df_3D, columns=['track_id','date_time', 'x', 'y', 'z'])

df_final_grouping = df_sort_time.reset_index(drop=True).groupby('track_id')
df_merged = [df_3D[i.values,:] for k,i in df_final_grouping.groups.items()]
array = np.array(df_merged, dtype=object)
df_pre_fly_times = pd.DataFrame(data=array)
# Array with grouped data
# Each item becomes part of a distinct group - not copies

# Total flying times
total_flight_time = []
for i in range (0, len(df_pre_fly_times)):
  time_1 = df_pre_fly_times [0] [i] [:,1] [0]
  time_2 = df_pre_fly_times [0] [i] [:,1] [-1]
  first_movement = dt.datetime.strptime(time_1, '%Y-%m-%d %H:%M:%S.%f')
  last_movement = dt.datetime.strptime(time_2, '%Y-%m-%d %H:%M:%S.%f')
  difference = last_movement - first_movement
  total_seconds = difference.total_seconds()
  total_flight_time.append(total_seconds)
total_flight_time

# Check how many entries there are for flight time
df_fly_time = pd.DataFrame(data=total_flight_time)
df_fly_time_array = np.array(df_fly_time, dtype=object)
df_fly_time.info()

# Create a list of all unique IDs
unique_id =[]
for i in range (0,len(df_pre_fly_times)):
  ids=df_pre_fly_times[0][i][0][0]
  unique_id.append(ids)
unique_id

# Check same number of entries as total times
df_unique_id = pd.DataFrame(data=unique_id)
array_unique_id = np.array(df_unique_id, dtype=str)
ids_list = list(df_unique_id[0])


# Need to combine in a dataframe with track ID - take out points under 1s
combined_array = np.column_stack((array_unique_id, df_fly_time_array))
combined_df = pd.DataFrame(combined_array, columns=['ID', 'flight_time'])
combined_df.info()
combined_df.head()

# Make flight time a float
combined_df[['flight_time']] = combined_df[['flight_time']].astype(float)
combined_df.info()

# Filter for over 1s flight time
onesec_filter = combined_df[combined_df['flight_time'] >= 1.0]


# Create a list of filtered and unique IDs for selection
array_combined_filtered = np.array(onesec_filter, dtype=object)
new_combined_df = pd.DataFrame(data=array_combined_filtered)
new_combined_df.head()

filtered_ids_list = list(new_combined_df[0])
print(filtered_ids_list)

# Compare IDs to use and then create file data set and filter with z & y

ids_coordinates = df_pre_fly[df_pre_fly['track_id'].isin(filtered_ids_list)]
ids_coordinates.head()

array_id_coordinates = np.array(ids_coordinates, dtype=object)
df_id_coordinates = pd.DataFrame(data=array_id_coordinates, columns=['track_id','date_time', 'x', 'y', 'z'])

df_id_coordinates['x'] = df_id_coordinates.x.astype(float)
df_id_coordinates['y'] = df_id_coordinates.y.astype(float)
df_id_coordinates['z'] = df_id_coordinates.z.astype(float)
df_id_coordinates['date_time'] = pd.to_datetime(df_id_coordinates['date_time'], format='%Y-%m-%d %H:%M:%S.%f')
n = 120
df_id_coordinates['date_time'] = df_id_coordinates['date_time'] + pd.DateOffset(minutes=n)
df_id_coordinates.info()

print(df_id_coordinates.y.min())
print(df_id_coordinates.y.max())

print(df_id_coordinates.z.min())
print(df_id_coordinates.z.max())


# CHANGE DATE FOR EACH FILE - CHECK FIRST TIME
df_id_coordinates = df_id_coordinates[df_id_coordinates['date_time'] >= '2022-07-14 18:00:00.0']
df_id_coordinates = df_id_coordinates[df_id_coordinates['date_time'] <= '2022-07-14 19:20:00.0']

df_id_coordinates.head(-5)

from pandas.core.series import Series

# Graphs - all points within five mins after timepoint
# Change to 1T to record minute by minute data
df_id_coordinates['quantity'] = 1
resampled = df_id_coordinates.resample('1T', on='date_time')
timepoints = resampled.quantity.sum()
timepoints.iloc[:].to_frame()

print(list(timepoints))

# First graphs
series = {}
for i, (date_time,df) in enumerate(resampled):
  series[i] = df

for i in series:
  t1_z = series[i].z
  t1_y = series[i].y
  # y axis needs to change per cage -12.5 for left and -15.5 for right
  heatmap, t1_zedges, t1_yedges = np.histogram2d(t1_z, t1_y, bins=[np.arange(180, 350, 1), np.arange(-12.5, 150, 1)])
  extent = [t1_zedges[0], t1_zedges[-1], t1_yedges[0], t1_yedges[-1]]
  plt.clf()
  fig = plt.imshow(heatmap.T, cmap=plt.cm.BuPu, extent=extent, origin='lower')

  # y axis needs to change per cage -12.5 for left and -15.5 for right
  plt.plot([234, 284], [-12.5,-12.5], linestyle='-', linewidth=6)
  clb = plt.colorbar()
  clb.ax.tick_params(labelsize=8)
  clb.ax.set_title('Number of tracked points', fontsize=8)
  # Set limit for comparison graphs
  plt.clim(0, 100)
  plt.xlabel("Cage length (z-axis cm)")
  plt.ylabel("Height from device (y-axis cm)")

  images_dir = '/content/drive/MyDrive/Datasets/summer_project_csv/QFS1_hetero_mixed/20220714_hetero_mixed_left/graphs/1_min'
  # CHANGE NAME EACH TIME
  plt.savefig(f"{images_dir}/20220714_hetero_mixed_left"+str(i)+".png", dpi=500)
  plt.show()